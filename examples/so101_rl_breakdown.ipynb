{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# SO101 Reinforcement Learning Demo\n",
    "## Understanding Observations and Actions for RL Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths and imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "sys.path.append(os.path.join(os.path.dirname(os.path.abspath('')), 'scripts'))\n",
    "\n",
    "from so101_sim import task_suite\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from image_utils import display_images, tensor_to_pil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Environment Setup for RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Failed to settle physics after 1 attempts of 2.0 seconds.\n",
      "Last residual velocity=0.00016584764048045787 and acceleration=0.5217454627473779.\n",
      "This suggests your dynamics are unstable. Consider:\n",
      "\t1. Increasing `max_settle_physics_attempts`\n",
      "\t2. Increasing `max_settle_physics_time`\n",
      "\t3. Tuning your contact parameters or initial pose distributions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment initialized!\n",
      "Reward: None\n",
      "Discount: None\n",
      "Observation keys: ['overhead_cam', 'side_cam', 'wrist_cam', 'commanded_joints_pos', 'joints_pos', 'joints_vel', 'physics_state', 'undelayed_joints_pos', 'undelayed_joints_vel', 'delayed_physics_state']\n"
     ]
    }
   ],
   "source": [
    "# Create RL environment\n",
    "env = task_suite.create_task_env(\n",
    "    task_name='SO100HandOverBanana',\n",
    "    time_limit=30.0,\n",
    "    cameras=('overhead_cam', 'side_cam', 'wrist_cam'),\n",
    "    camera_resolution=(480, 848),\n",
    "    image_observation_enabled=True,\n",
    ")\n",
    "\n",
    "# Get initial observation\n",
    "timestep = env.reset()\n",
    "obs = timestep.observation\n",
    "\n",
    "print(\"Environment initialized!\")\n",
    "print(f\"Reward: {timestep.reward}\")\n",
    "print(f\"Discount: {timestep.discount}\")\n",
    "print(f\"Observation keys: {list(obs.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Understanding Observation Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RL OBSERVATION ANALYSIS ===\n",
      "\n",
      "ðŸ¤– JOINT OBSERVATIONS:\n",
      "joints_pos (actual):     [0. 0. 0. 0. 0. 0.] [6D state]\n",
      "commanded_joints_pos:    [ 0.      -1.57079  1.57079  1.57079 -1.57079  0.     ] [6D targets]\n",
      "undelayed_joints_pos:    [0. 0. 0. 0. 0. 0.] [6D immediate]\n",
      "\n",
      "ðŸ“· VISUAL OBSERVATIONS:\n",
      "overhead_cam   : (480, 848, 3) [1221120 pixels]\n",
      "side_cam       : (480, 848, 3) [1221120 pixels]\n",
      "wrist_cam      : (480, 848, 3) [1221120 pixels]\n",
      "\n",
      "ðŸ”¬ PHYSICS STATE:\n",
      "physics_state:           (38,) [full sim state]\n",
      "delayed_physics_state:   (38,) [delayed sim state]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'overhead_cam': array([[[  1, 205, 255],\n",
       "         [  1, 205, 255],\n",
       "         [  1, 205, 255],\n",
       "         ...,\n",
       "         [255, 255, 178],\n",
       "         [255, 255, 178],\n",
       "         [255, 255, 178]],\n",
       " \n",
       "        [[  1, 205, 255],\n",
       "         [  1, 205, 255],\n",
       "         [  1, 205, 255],\n",
       "         ...,\n",
       "         [255, 255, 178],\n",
       "         [255, 255, 178],\n",
       "         [255, 255, 178]],\n",
       " \n",
       "        [[  1, 205, 255],\n",
       "         [  1, 205, 255],\n",
       "         [  1, 205, 255],\n",
       "         ...,\n",
       "         [255, 255, 178],\n",
       "         [255, 255, 178],\n",
       "         [255, 255, 178]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[150, 188, 209],\n",
       "         [149, 187, 208],\n",
       "         [148, 186, 207],\n",
       "         ...,\n",
       "         [255, 246, 165],\n",
       "         [255, 246, 165],\n",
       "         [255, 246, 165]],\n",
       " \n",
       "        [[149, 186, 207],\n",
       "         [148, 185, 206],\n",
       "         [147, 183, 204],\n",
       "         ...,\n",
       "         [255, 246, 165],\n",
       "         [255, 246, 165],\n",
       "         [255, 246, 165]],\n",
       " \n",
       "        [[147, 184, 204],\n",
       "         [147, 185, 205],\n",
       "         [149, 188, 209],\n",
       "         ...,\n",
       "         [255, 246, 165],\n",
       "         [255, 246, 165],\n",
       "         [255, 246, 164]]], dtype=uint8),\n",
       " 'side_cam': array([[[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 200, 133],\n",
       "         [255, 200, 133],\n",
       "         [255, 200, 133],\n",
       "         ...,\n",
       "         [255, 208, 138],\n",
       "         [255, 208, 138],\n",
       "         [255, 208, 138]],\n",
       " \n",
       "        [[255, 200, 133],\n",
       "         [255, 200, 133],\n",
       "         [255, 200, 133],\n",
       "         ...,\n",
       "         [255, 208, 138],\n",
       "         [255, 208, 138],\n",
       "         [255, 208, 138]],\n",
       " \n",
       "        [[255, 200, 133],\n",
       "         [255, 200, 133],\n",
       "         [255, 200, 133],\n",
       "         ...,\n",
       "         [255, 208, 138],\n",
       "         [255, 208, 138],\n",
       "         [255, 208, 138]]], dtype=uint8),\n",
       " 'wrist_cam': array([[[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [235, 177, 118],\n",
       "         [235, 177, 118],\n",
       "         [235, 177, 118]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [235, 177, 118],\n",
       "         [235, 177, 118],\n",
       "         [235, 177, 118]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [235, 177, 118],\n",
       "         [235, 177, 118],\n",
       "         [235, 177, 118]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [245, 184, 122],\n",
       "         [245, 184, 122],\n",
       "         [245, 184, 122]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [245, 184, 122],\n",
       "         [245, 184, 122],\n",
       "         [245, 184, 122]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [245, 184, 122],\n",
       "         [245, 184, 122],\n",
       "         [245, 184, 122]]], dtype=uint8),\n",
       " 'commanded_joints_pos': array([ 0.     , -1.57079,  1.57079,  1.57079, -1.57079,  0.     ]),\n",
       " 'joints_pos': array([0., 0., 0., 0., 0., 0.]),\n",
       " 'joints_vel': array([], dtype=float64),\n",
       " 'physics_state': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.87066700e-01, -2.85441662e-02,\n",
       "         4.21710145e-01,  9.88904794e-01, -1.17948861e-04,  1.73709869e-04,\n",
       "        -1.48550547e-01, -2.46765002e-01,  1.28320234e-02,  4.30587635e-01,\n",
       "         9.99536672e-01,  2.73944377e-02, -1.32656262e-02, -9.92139827e-05,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  8.57049218e-08, -7.78859743e-08,\n",
       "        -6.30368357e-07,  2.81794777e-05,  5.98860954e-05,  3.03557113e-08,\n",
       "        -1.67699176e-05, -4.37808047e-05, -4.76385191e-05, -1.65847640e-04,\n",
       "        -1.30157771e-04, -1.76380051e-05]),\n",
       " 'undelayed_joints_pos': array([0., 0., 0., 0., 0., 0.]),\n",
       " 'undelayed_joints_vel': array([], dtype=float64),\n",
       " 'delayed_physics_state': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.87066700e-01, -2.85441662e-02,\n",
       "         4.21710145e-01,  9.88904794e-01, -1.17948861e-04,  1.73709869e-04,\n",
       "        -1.48550547e-01, -2.46765002e-01,  1.28320234e-02,  4.30587635e-01,\n",
       "         9.99536672e-01,  2.73944377e-02, -1.32656262e-02, -9.92139827e-05,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  8.57049218e-08, -7.78859743e-08,\n",
       "        -6.30368357e-07,  2.81794777e-05,  5.98860954e-05,  3.03557113e-08,\n",
       "        -1.67699176e-05, -4.37808047e-05, -4.76385191e-05, -1.65847640e-04,\n",
       "        -1.30157771e-04, -1.76380051e-05])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_observation(obs):\n",
    "    \"\"\"Analyze and explain observation structure for RL.\"\"\"\n",
    "    print(\"=== RL OBSERVATION ANALYSIS ===\")\n",
    "    \n",
    "    # Joint observations (most important for RL)\n",
    "    print("\nJOINT OBSERVATIONS:")\n",
    "    print(f\"joints_pos (actual):     {obs['joints_pos']} [6D state]\")\n",
    "    print(f\"commanded_joints_pos:    {obs['commanded_joints_pos']} [6D targets]\")\n",
    "    print(f\"undelayed_joints_pos:    {obs['undelayed_joints_pos']} [6D immediate]\")\n",
    "    \n",
    "    # Camera observations  \n",
    "    print("\nVISUAL OBSERVATIONS:")\n",
    "    for cam in ['overhead_cam', 'side_cam', 'wrist_cam']:\n",
    "        if cam in obs:\n",
    "            shape = obs[cam].shape\n",
    "            print(f\"{cam:15}: {shape} [{shape[0]*shape[1]*shape[2]} pixels]\")\n",
    "    \n",
    "    # Physics state\n",
    "    print("\nPHYSICS STATE:")\n",
    "    print(f\"physics_state:           {obs['physics_state'].shape} [full sim state]\")\n",
    "    print(f\"delayed_physics_state:   {obs['delayed_physics_state'].shape} [delayed sim state]\")\n",
    "    \n",
    "    return obs\n",
    "\n",
    "analyze_observation(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Action Space for RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RL ACTION SPACE ===\n",
      "Action shape: (6,)\n",
      "Action dtype: float32\n",
      "Action bounds: [-3.14, 3.14]\n",
      "\n",
      "ðŸŽ® ACTION MAPPING:\n",
      "action[0] = rotation     | range: [ -3.14,   3.14]\n",
      "action[1] = pitch        | range: [ -3.14,   3.14]\n",
      "action[2] = elbow        | range: [ -3.14,   3.14]\n",
      "action[3] = wrist_pitch  | range: [ -3.14,   3.14]\n",
      "action[4] = wrist_roll   | range: [ -3.14,   3.14]\n",
      "action[5] = jaw          | range: [  0.00,   0.08]\n"
     ]
    }
   ],
   "source": [
    "def analyze_action_space(env):\n",
    "    \"\"\"Analyze action space for RL algorithms.\"\"\"\n",
    "    action_spec = env.action_spec()\n",
    "    \n",
    "    print(\"=== RL ACTION SPACE ===\")\n",
    "    print(f\"Action shape: {action_spec.shape}\")\n",
    "    print(f\"Action dtype: {action_spec.dtype}\")\n",
    "    print(f\"Action bounds: [{action_spec.minimum[0]:.2f}, {action_spec.maximum[0]:.2f}]\")\n",
    "    \n",
    print("\nACTION MAPPING:")
    "    action_names = ['rotation', 'pitch', 'elbow', 'wrist_pitch', 'wrist_roll', 'jaw']\n",
    "    for i, name in enumerate(action_names):\n",
    "        print(f\"action[{i}] = {name:12} | range: [{action_spec.minimum[i]:6.2f}, {action_spec.maximum[i]:6.2f}]\")\n",
    "    \n",
    "    return action_spec\n",
    "\n",
    "action_spec = analyze_action_space(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. RL Episode Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RL EPISODE SIMULATION ===\n",
      "Step  0 | Action: [-0.8391829   0.42618219 -0.91514084  0.14694909  0.0992995   0.01694754] | Reward: 0.000\n",
      "Step  1 | Action: [-0.39156843  0.48427199  0.74281886  0.7565855   0.11973565  0.01177233] | Reward: 0.000\n",
      "Step  2 | Action: [-0.21104661 -0.14842907  0.42365505  0.80106162 -0.76538231  0.01697472] | Reward: 0.000\n",
      "Step  3 | Action: [ 0.16024267  0.06257495  0.75058748 -0.17345165  0.18857608  0.02126437] | Reward: 0.000\n",
      "Step  4 | Action: [ 0.1554716   0.2782635  -0.32441851 -0.05781743  0.72900764  0.01857672] | Reward: 0.000\n"
     ]
    }
   ],
   "source": [
    "def run_rl_episode(env, num_steps=10):\n",
    "    \"\"\"Simulate an RL episode with random actions.\"\"\"\n",
    "    print(\"=== RL EPISODE SIMULATION ===\")\n",
    "    \n",
    "    # Reset environment\n",
    "    timestep = env.reset()\n",
    "    \n",
    "    episode_data = {\n",
    "        'observations': [],\n",
    "        'actions': [],\n",
    "        'rewards': [],\n",
    "        'discounts': []\n",
    "    }\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # Random action (RL agent would generate this)\n",
    "        action = np.random.uniform(\n",
    "            low=action_spec.minimum, \n",
    "            high=action_spec.maximum, \n",
    "            size=action_spec.shape\n",
    "        ) * 0.3  # Scale down for safety\n",
    "        \n",
    "        # Execute action\n",
    "        timestep = env.step(action)\n",
    "        \n",
    "        # Store transition data\n",
    "        episode_data['observations'].append(timestep.observation)\n",
    "        episode_data['actions'].append(action)\n",
    "        episode_data['rewards'].append(timestep.reward)\n",
    "        episode_data['discounts'].append(timestep.discount)\n",
    "        \n",
    "        print(f\"Step {step:2d} | Action: {action} | Reward: {timestep.reward:.3f}\")\n",
    "        \n",
    "        # Check if episode terminated\n",
    "        if timestep.last():\n",
    "            print(f\"Episode terminated at step {step}\")\n",
    "            break\n",
    "    \n",
    "    return episode_data\n",
    "\n",
    "# Run sample episode\n",
    "episode_data = run_rl_episode(env, num_steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Observation Processing for RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RL STATE REPRESENTATIONS ===\n",
      "Joints only:       (6,) | [0. 0. 0. 0. 0. 0.]\n",
      "Joints + targets:  (12,) | Values: 12 elements\n",
      "Full physics:      (38,) | Values: 38 elements\n"
     ]
    }
   ],
   "source": [
    "def extract_rl_state(obs, state_type='joints_only'):\n",
    "    \"\"\"Extract relevant state representation for RL algorithms.\"\"\"\n",
    "    \n",
    "    if state_type == 'joints_only':\n",
    "        # Simple joint positions (most common for RL)\n",
    "        state = obs['joints_pos']  # Shape: (6,)\n",
    "        \n",
    "    elif state_type == 'joints_with_targets':\n",
    "        # Joint positions + commanded positions\n",
    "        state = np.concatenate([\n",
    "            obs['joints_pos'],\n",
    "            obs['commanded_joints_pos']\n",
    "        ])  # Shape: (12,)\n",
    "        \n",
    "    elif state_type == 'full_physics':\n",
    "        # Full physics state (high-dimensional)\n",
    "        state = obs['physics_state']  # Shape: (38,)\n",
    "        \n",
    "    elif state_type == 'visual':\n",
    "        # Use camera observations (requires CNN)\n",
    "        state = obs['overhead_cam']  # Shape: (480, 848, 3)\n",
    "        \n",
    "    elif state_type == 'multimodal':\n",
    "        # Combination of joints + visual (advanced)\n",
    "        joints = obs['joints_pos']\n",
    "        visual = obs['overhead_cam']\n",
    "        state = {'joints': joints, 'visual': visual}\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Test different state representations\n",
    "print(\"=== RL STATE REPRESENTATIONS ===\")\n",
    "current_obs = episode_data['observations'][0]\n",
    "\n",
    "state_joints = extract_rl_state(current_obs, 'joints_only')\n",
    "state_extended = extract_rl_state(current_obs, 'joints_with_targets')\n",
    "state_physics = extract_rl_state(current_obs, 'full_physics')\n",
    "\n",
    "print(f\"Joints only:       {state_joints.shape} | {state_joints}\")\n",
    "print(f\"Joints + targets:  {state_extended.shape} | Values: {len(state_extended)} elements\")\n",
    "print(f\"Full physics:      {state_physics.shape} | Values: {len(state_physics)} elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6. Reward Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REWARD ANALYSIS ===\n",
      "Total steps: 5\n",
      "Reward range: [0.000, 0.000]\n",
      "Total return: 0.000\n",
      "Average reward: 0.000\n",
      "\n",
      "Step-by-step rewards:\n",
      "  Step 0: 0.000\n",
      "  Step 1: 0.000\n",
      "  Step 2: 0.000\n",
      "  Step 3: 0.000\n",
      "  Step 4: 0.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def analyze_rewards(episode_data):\n",
    "    \"\"\"Analyze reward structure for RL training.\"\"\"\n",
    "    rewards = episode_data['rewards']\n",
    "    \n",
    "    print(\"=== REWARD ANALYSIS ===\")\n",
    "    print(f\"Total steps: {len(rewards)}\")\n",
    "    print(f\"Reward range: [{min(rewards):.3f}, {max(rewards):.3f}]\")\n",
    "    print(f\"Total return: {sum(rewards):.3f}\")\n",
    "    print(f\"Average reward: {np.mean(rewards):.3f}\")\n",
    "    \n",
    "    print(\"\\nStep-by-step rewards:\")\n",
    "    for i, reward in enumerate(rewards):\n",
    "        print(f\"  Step {i}: {reward:.3f}\")\n",
    "    \n",
    "    # Plot rewards\n",
    "    if len(rewards) > 1:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(rewards, 'b-o')\n",
    "        plt.title('Rewards per Step')\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel('Reward')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "analyze_rewards(episode_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 7. RL Training Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_rl_training(episode_data, state_type='joints_only'):\n",
    "    \"\"\"Format episode data for RL algorithm training.\"\"\"\n",
    "    \n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    next_states = []\n",
    "    dones = []\n",
    "    \n",
    "    observations = episode_data['observations']\n",
    "    \n",
    "    for i in range(len(observations) - 1):\n",
    "        # Current state\n",
    "        state = extract_rl_state(observations[i], state_type)\n",
    "        states.append(state)\n",
    "        \n",
    "        # Action taken\n",
    "        action = episode_data['actions'][i]\n",
    "        actions.append(action)\n",
    "        \n",
    "        # Reward received\n",
    "        reward = episode_data['rewards'][i]\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        # Next state\n",
    "        next_state = extract_rl_state(observations[i + 1], state_type)\n",
    "        next_states.append(next_state)\n",
    "        \n",
    "        # Done flag (episode termination)\n",
    "        done = episode_data['discounts'][i] == 0.0\n",
    "        dones.append(done)\n",
    "    \n",
    "    return {\n",
    "        'states': np.array(states),\n",
    "        'actions': np.array(actions),\n",
    "        'rewards': np.array(rewards),\n",
    "        'next_states': np.array(next_states),\n",
    "        'dones': np.array(dones)\n",
    "    }\n",
    "\n",
    "# Format data for training\n",
    "training_data = format_for_rl_training(episode_data, 'joints_only')\n",
    "\n",
    "print(\"=== RL TRAINING DATA FORMAT ===\")\n",
    "for key, value in training_data.items():\n",
    "    print(f\"{key:12}: {value.shape} | dtype: {value.dtype}\")\n",
    "\n",
    "print(\"\\nExample transition:\")\n",
    "if len(training_data['states']) > 0:\n",
    "    print(f\"State:      {training_data['states'][0]}\")\n",
    "    print(f\"Action:     {training_data['actions'][0]}\")\n",
    "    print(f\"Reward:     {training_data['rewards'][0]}\")\n",
    "    print(f\"Next State: {training_data['next_states'][0]}\")\n",
    "    print(f\"Done:       {training_data['dones'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 8. RL Algorithm Integration Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rl_environment_wrapper():\n",
    "    \"\"\"Create a standardized RL environment wrapper.\"\"\"\n",
    "    \n",
    "    class SO101_RL_Env:\n",
    "        def __init__(self, state_type='joints_only'):\n",
    "            self.env = task_suite.create_task_env(\n",
    "                task_name='SO100HandOverBanana',\n",
    "                time_limit=30.0,\n",
    "                cameras=('overhead_cam',) if state_type != 'visual' else ('overhead_cam', 'side_cam', 'wrist_cam'),\n",
    "                image_observation_enabled=True if state_type == 'visual' else False,\n",
    "            )\n",
    "            self.state_type = state_type\n",
    "            self.action_space_size = 6\n",
    "            \n",
    "            # Determine state space size\n",
    "            if state_type == 'joints_only':\n",
    "                self.state_space_size = 6\n",
    "            elif state_type == 'joints_with_targets':\n",
    "                self.state_space_size = 12\n",
    "            elif state_type == 'full_physics':\n",
    "                self.state_space_size = 38\n",
    "            elif state_type == 'visual':\n",
    "                self.state_space_size = (480, 848, 3)  # Image dimensions\n",
    "        \n",
    "        def reset(self):\n",
    "            timestep = self.env.reset()\n",
    "            state = extract_rl_state(timestep.observation, self.state_type)\n",
    "            return state\n",
    "        \n",
    "        def step(self, action):\n",
    "            timestep = self.env.step(action)\n",
    "            state = extract_rl_state(timestep.observation, self.state_type)\n",
    "            reward = timestep.reward\n",
    "            done = timestep.last()\n",
    "            info = {'discount': timestep.discount}\n",
    "            return state, reward, done, info\n",
    "        \n",
    "        def get_specs(self):\n",
    "            return {\n",
    "                'state_space': self.state_space_size,\n",
    "                'action_space': self.action_space_size,\n",
    "                'action_bounds': (-3.14, 3.14)  # Approximate joint limits\n",
    "            }\n",
    "    \n",
    "    return SO101_RL_Env\n",
    "\n",
    "# Example usage\n",
    "RL_Env = create_rl_environment_wrapper()\n",
    "rl_env = RL_Env(state_type='joints_only')\n",
    "\n",
    "print(\"=== RL ENVIRONMENT WRAPPER ===\")\n",
    "specs = rl_env.get_specs()\n",
    "print(f\"State space size: {specs['state_space']}\")\n",
    "print(f\"Action space size: {specs['action_space']}\")\n",
    "print(f\"Action bounds: {specs['action_bounds']}\")\n",
    "\n",
    "# Test the wrapper\n",
    "state = rl_env.reset()\n",
    "print(f\"\\nInitial state: {state}\")\n",
    "\n",
    "action = np.random.uniform(-0.1, 0.1, size=6)\n",
    "next_state, reward, done, info = rl_env.step(action)\n",
    "print(f\"After action {action}:\")\n",
    "print(f\"  Next state: {next_state}\")\n",
    "print(f\"  Reward: {reward}\")\n",
    "print(f\"  Done: {done}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Summary for RL Development\n",
    "\n",
    "### Key Observations for RL:\n",
    "- **`joints_pos`**: Primary state representation (6D joint positions)\n",
    "- **`commanded_joints_pos`**: Target positions (useful for control-aware RL)\n",
    "- **Camera observations**: For vision-based RL (requires CNN)\n",
    "- **`physics_state`**: Full simulation state (38D, high-dimensional)\n",
    "\n",
    "### Recommended RL State Representations:\n",
    "1. **Simple**: `joints_pos` (6D) - Start here\n",
    "2. **Extended**: `joints_pos + commanded_joints_pos` (12D)\n",
    "3. **Visual**: Camera images (requires CNN architectures)\n",
    "4. **Full**: `physics_state` (38D, for complex tasks)\n",
    "\n",
    "### Action Space:\n",
    "- 6D continuous actions: `[rotation, pitch, elbow, wrist_pitch, wrist_roll, jaw]`\n",
    "- Bounded approximately in `[-Ï€, Ï€]` range\n",
    "- Use action scaling for stable training\n",
    "\n",
    "### Next Steps:\n",
    "1. Choose state representation based on your RL algorithm\n",
    "2. Implement reward shaping for your specific task\n",
    "3. Use the environment wrapper for standard RL libraries (OpenAI Gym, Stable-Baselines3, etc.)\n",
    "4. Consider action space normalization for better training stability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caferacer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
